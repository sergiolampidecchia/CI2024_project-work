{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic Regression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from icecream import ic\n",
    "from gxgp.node import Node as GXNode\n",
    "from gxgp.draw import draw\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "data = np.load('../data/problem_6.npz')  \n",
    "x_validation = data['x'] \n",
    "y_validation = data['y']\n",
    "\n",
    "num_vars = x_validation.shape[0]\n",
    "VARIABLES = [f\"x{i}\" for i in range(num_vars)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Node Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, value, children=None):\n",
    "        \"\"\"\n",
    "        value could be:\n",
    "            - a float (constant);\n",
    "            - a string (a variable name like 'x0','x1', ...):\n",
    "            - a Python function ( math.sin, operator.add, ...)\n",
    "        \"\"\"\n",
    "        self.value = value\n",
    "        self.children = children if children is not None else []\n",
    "    \n",
    "    def is_leaf(self):\n",
    "        return len(self.children) == 0\n",
    "    \n",
    "    def __str__(self):\n",
    "        if self.is_leaf():\n",
    "            return str(self.value)\n",
    "        else:\n",
    "            return f\"({self.value} {' '.join(map(str, self.children))})\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Node Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_children(node: Node, x: np.ndarray) -> np.ndarray:\n",
    "    if node.is_leaf():\n",
    "        val = node.value\n",
    "        \n",
    "        if isinstance(val, (int, float)):\n",
    "            return np.full(x.shape[1], float(val))\n",
    "        \n",
    "        if isinstance(val, str) and val in VARIABLES:\n",
    "            try:\n",
    "                idx = VARIABLES.index(val)\n",
    "            except ValueError:\n",
    "                raise ValueError(f\"Unknown Variable: {val}\")\n",
    "            return x[idx, :]\n",
    "          \n",
    "        raise ValueError(f\"Unknown leaf value: {val}\")\n",
    "    \n",
    "    else:\n",
    "        op = node.value\n",
    "        children_values = [evaluate_children(child, x) for child in node.children]\n",
    "\n",
    "        if len(children_values) == 1:\n",
    "            return safe_apply_unary(op, children_values[0])\n",
    "        elif len(children_values) == 2:\n",
    "            return safe_apply_binary(op, children_values[0], children_values[1])\n",
    "        else:\n",
    "            raise ValueError(\"Children number not supported\")\n",
    "\n",
    "def safe_apply_unary(func, arr):\n",
    "    try:\n",
    "        return func(arr)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Unary operator {func} failed with error: {e}\") \n",
    "\n",
    "def safe_apply_binary(func, arr1, arr2):\n",
    "    try:\n",
    "        return func(arr1, arr2)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Binary operator {func} failed with error: {e}\") \n",
    "\n",
    "\n",
    "DEPTH_MAX = 6\n",
    "CONST_MAX = 10\n",
    "CONST_MIN = -10\n",
    "\n",
    "def sin_fn(x): return np.sin(x)\n",
    "def cos_fn(x): return np.cos(x)\n",
    "def neg_fn(x): return -x\n",
    "def abs_fn(x): return np.abs(x)\n",
    "def log_safe(x): return np.where(x <= 0, 0.0, np.log(x))\n",
    "def sqrt_safe(x): return np.sqrt(np.abs(x))\n",
    "def exp_safe(x): return np.exp(np.clip(x, -700, 700))\n",
    "\n",
    "def add_fn(a, b): return a + b\n",
    "def sub_fn(a, b): return a - b\n",
    "def mul_fn(a, b): return a * b\n",
    "def div_safe(a, b): return np.where(np.abs(b) < 1e-12, 1.0, a / b)\n",
    "\n",
    "def create_function_set_with_weights() -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Creates a weighted function set from unary and binary functions.\n",
    "    Returns a list of dictionaries each describing a function.\n",
    "    \"\"\"\n",
    "\n",
    "    function_set = []\n",
    "\n",
    "    function_set.extend([\n",
    "        {'function': add_fn, 'arity': 2, 'symbol': '+', 'weight': 1.0},\n",
    "        {'function': sub_fn, 'arity': 2, 'symbol': '-', 'weight': 1.0},\n",
    "        {'function': mul_fn, 'arity': 2, 'symbol': '*', 'weight': 1.0},\n",
    "        {'function': div_safe, 'arity': 2, 'symbol': '/', 'weight': 0.7},  \n",
    "    ])\n",
    "\n",
    "    function_set.extend([\n",
    "        {'function': sin_fn, 'arity': 1, 'symbol': 'sin', 'weight': 0.6},\n",
    "        {'function': cos_fn, 'arity': 1, 'symbol': 'cos', 'weight': 0.6},\n",
    "        {'function': neg_fn, 'arity': 1, 'symbol': 'neg', 'weight': 0.8},\n",
    "        {'function': abs_fn, 'arity': 1, 'symbol': 'abs', 'weight': 0.9},\n",
    "        {'function': log_safe, 'arity': 1, 'symbol': 'log', 'weight': 0.5},\n",
    "        {'function': sqrt_safe, 'arity': 1, 'symbol': 'sqrt', 'weight': 0.6},\n",
    "        {'function': exp_safe, 'arity': 1, 'symbol': 'exp', 'weight': 0.4}, \n",
    "    ])\n",
    "\n",
    "    return function_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_SET = create_function_set_with_weights()\n",
    "UNARY_FUNCS = [f for f in FUNCTION_SET if f['arity'] == 1 and f['weight'] > 0.0]\n",
    "BINARY_FUNCS = [f for f in FUNCTION_SET if f['arity'] == 2 and f['weight'] > 0.0]\n",
    "\n",
    "def generate_subtree(\n",
    "    depth: int,\n",
    "    force_var: Optional[str] = None,  \n",
    "    constant_min=CONST_MIN,\n",
    "    constant_max=CONST_MAX\n",
    ") -> Node:\n",
    "    \"\"\"\n",
    "    Generate recursively a subtree with a variable var at the root.\n",
    "    \"\"\"\n",
    "    if depth <= 0:\n",
    "        if force_var is not None:\n",
    "            return Node(force_var)\n",
    "        elif random.random() < 0.5 and VARIABLES:\n",
    "            return Node(random.choice(VARIABLES))\n",
    "        else:\n",
    "            return Node(random.uniform(constant_min, constant_max))\n",
    "        \n",
    "    if random.random() < 0.3 and UNARY_FUNCS:\n",
    "        op_dict = random.choices(\n",
    "            UNARY_FUNCS,\n",
    "            weights=[f['weight'] for f in UNARY_FUNCS],\n",
    "            k=1\n",
    "        )[0]\n",
    "        child = generate_subtree(depth - 1, force_var, constant_min, constant_max)\n",
    "        return Node(op_dict['function'], [child])\n",
    "    \n",
    "    else:\n",
    "        op_dict = random.choices(\n",
    "            BINARY_FUNCS,\n",
    "            weights=[f['weight'] for f in BINARY_FUNCS],\n",
    "            k=1\n",
    "        )[0]\n",
    "        left = generate_subtree(depth - 1, force_var, constant_min, constant_max)\n",
    "        right = generate_subtree(depth - 1, None, constant_min, constant_max)\n",
    "        return Node(op_dict['function'], [left, right])\n",
    "\n",
    "def generate_random_tree(\n",
    "        depth=DEPTH_MAX, \n",
    "        constant_min=CONST_MIN, \n",
    "        constant_max=CONST_MAX\n",
    ") -> Node:\n",
    "    \"\"\"\n",
    "    Generate a tree which includes all the variables.\n",
    "    \"\"\"\n",
    "    if not VARIABLES:\n",
    "        raise ValueError(\"There is no variable available.\")\n",
    "    elif len(VARIABLES) == 1:\n",
    "        return generate_subtree(depth, force_var=VARIABLES[0], constant_min=constant_min, constant_max=constant_max)\n",
    "    else:\n",
    "        return generate_subtree(depth, force_var=random.choice(VARIABLES), constant_min=constant_min, constant_max=constant_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expression String Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_safe = lambda x: np.where(x <= 0, 0.0, np.log(x))\n",
    "sqrt_safe = lambda x: np.sqrt(np.abs(x))\n",
    "exp_safe = lambda x: np.exp(np.clip(x, -700, 700))\n",
    "div_safe = lambda a, b: np.where(np.abs(b) < 1e-12, 1.0, a / b)\n",
    "\n",
    "DISPLAY_NAME_MAP = {\n",
    "    id(np.add): '+', \n",
    "    id(np.subtract): '-', \n",
    "    id(np.multiply): '*', \n",
    "    id(np.sin): 'sin',\n",
    "    id(np.cos): 'cos',\n",
    "    id(np.negative): 'neg',\n",
    "    id(np.abs): 'abs',\n",
    "    id(log_safe): 'log',\n",
    "    id(sqrt_safe): 'sqrt',\n",
    "    id(exp_safe): 'exp',\n",
    "    id(div_safe): '/',\n",
    "}\n",
    "\n",
    "def tree_to_string(node: Node) -> str:\n",
    "    \"\"\" It Returns a string representation of the tree node \"\"\"\n",
    "    if node.is_leaf():\n",
    "        val = node.value\n",
    "        if isinstance(val, (float, int)) and not isinstance(val, bool):\n",
    "            return f\"{float(val):.3f}\"\n",
    "        if isinstance(val, str):\n",
    "            idx = val[1]  \n",
    "            return f\"x{idx}\"\n",
    "        return str(val)\n",
    "\n",
    "    op = node.value\n",
    "    op_name = DISPLAY_NAME_MAP.get(id(op), getattr(op, '__name__', str(op)))\n",
    "    child_strs = [tree_to_string(child) for child in node.children]\n",
    "    if len(child_strs) == 1:\n",
    "        return f\"{op_name}({child_strs[0]})\"\n",
    "    elif len(child_strs) == 2:\n",
    "        return f\"({child_strs[0]} {op_name} {child_strs[1]})\"\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported number of children\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_var_func(var_name: str):\n",
    "    \"\"\"It creates a function that returns the value of a variable from the keyword arguments.\"\"\"\n",
    "    def var_func(**kwargs):\n",
    "        return kwargs[var_name]\n",
    "    var_func.__name__ = var_name\n",
    "    return var_func\n",
    "\n",
    "def make_const_func(const_val: float):\n",
    "    \"\"\"It creates a function that returns a constant value.\"\"\"\n",
    "    def const_func(**kwargs):\n",
    "        return const_val\n",
    "    const_func.__name__ = f\"{const_val:.3f}\"\n",
    "    return const_func\n",
    "\n",
    "def convert_to_gxgp_node(my_node, subtree=None) -> GXNode:\n",
    "    \"\"\"\n",
    "    It converts a Node object to a GXNode object.\n",
    "    \"\"\"\n",
    "    if subtree is None:\n",
    "        subtree = set()\n",
    "\n",
    "    if my_node.is_leaf():\n",
    "        val = my_node.value\n",
    "        if isinstance(val, str):\n",
    "            var_func = make_var_func(val)\n",
    "            gx_node = GXNode(var_func, [], name=val)      \n",
    "        else:\n",
    "            const_func = make_const_func(float(val))\n",
    "            gx_node = GXNode(const_func, [], name=f\"{float(val):.3f}\") \n",
    "        subtree.add(gx_node)\n",
    "        return gx_node\n",
    "    \n",
    "    \n",
    "    op = my_node.value\n",
    "    converted_children = []\n",
    "    op_name = DISPLAY_NAME_MAP.get(id(op), getattr(op, '__name__', str(op)))\n",
    "    for child in my_node.children if my_node.children is not None else []:\n",
    "        converted_child = convert_to_gxgp_node(child, subtree)\n",
    "        converted_children.append(converted_child)\n",
    "\n",
    "    gx_node = GXNode(op, converted_children, name=op_name)\n",
    "    subtree.add(gx_node)\n",
    "    return gx_node\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(individual: Node, x: np.ndarray, y: np.ndarray, penalty_factor: float = 0.001) -> float:\n",
    "    \"\"\" It calculates the fitness of an individual. \"\"\"\n",
    "    try:\n",
    "        y_pred = evaluate_children(individual, x)\n",
    "        if not np.all(np.isfinite(y_pred)):\n",
    "            return 1e10 \n",
    "        mse = np.mean((y - y_pred) ** 2)\n",
    "        complexity_penalty = penalty_factor * len(get_all_nodes(individual))\n",
    "        return mse \n",
    "    \n",
    "    except Exception as e:\n",
    "        return 1e10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection(population, x, y, k=3):\n",
    "    \"\"\" It returns the best individual from a random tournament. \"\"\"\n",
    "    if len(population) < k:\n",
    "        contenders = population\n",
    "    else:\n",
    "        contenders = random.sample(population, k)\n",
    "    best = min(contenders, key=lambda ind: fitness(ind, x, y))\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossover Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1: Node, parent2: Node) -> Node:\n",
    "    \"\"\"Crossover between two parents.\"\"\"\n",
    "    child1 = clone_tree(parent1)\n",
    "    child2 = clone_tree(parent2)\n",
    "    \n",
    "    internal_nodes1 = [node for node in get_all_nodes(child1) if not node.is_leaf()]\n",
    "    internal_nodes2 = [node for node in get_all_nodes(child2) if not node.is_leaf()]\n",
    "    \n",
    "    if internal_nodes1 and internal_nodes2:\n",
    "        node1 = random.choice(internal_nodes1)\n",
    "        node2 = random.choice(internal_nodes2)\n",
    "    \n",
    "        node1.value, node1.children, node2.value, node2.children = node2.value, node2.children, node1.value, node1.children\n",
    "    \n",
    "    return child1\n",
    "\n",
    "\n",
    "def get_random_node(tree: Node) -> Node:\n",
    "    \"\"\" It returns a random node from the tree. \"\"\"\n",
    "    all_nodes = get_all_nodes(tree)\n",
    "    return random.choice(all_nodes)\n",
    "\n",
    "def get_all_nodes(tree: Node) -> list:\n",
    "    \"\"\" It returns a list with all the nodes of the tree. \"\"\"\n",
    "    nodes = [tree]\n",
    "    for c in tree.children:\n",
    "        nodes += get_all_nodes(c)\n",
    "    return nodes\n",
    "\n",
    "def clone_tree(node: Node) -> Node:\n",
    "    \"\"\" It creates a deep copy of the tree. \"\"\"\n",
    "    new_node = Node(node.value)\n",
    "    new_node.children = [clone_tree(c) for c in node.children]\n",
    "    return new_node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(individual: Node, mutation_rate=0.4) -> Node:\n",
    "    \"\"\"With a certain probability it mutates a node of the tree.\"\"\"\n",
    "    mutant = clone_tree(individual)\n",
    "    if random.random() < mutation_rate:\n",
    "        internal_nodes = [node for node in get_all_nodes(mutant) if not node.is_leaf()]\n",
    "        leaf_nodes = [node for node in get_all_nodes(mutant) if node.is_leaf()]\n",
    "        \n",
    "        if internal_nodes and (not leaf_nodes or random.random() < 0.5):\n",
    "            \n",
    "            node_to_mutate = random.choice(internal_nodes)\n",
    "            new_subtree = generate_random_tree(depth=DEPTH_MAX, constant_min=CONST_MIN, constant_max=CONST_MAX)\n",
    "            node_to_mutate.value = new_subtree.value\n",
    "            node_to_mutate.children = new_subtree.children\n",
    "        elif leaf_nodes:\n",
    "            node_to_mutate = random.choice(leaf_nodes)\n",
    "            if random.random() < 0.5:\n",
    "                new_var = random.choice(VARIABLES)\n",
    "                node_to_mutate.value = new_var\n",
    "            else:\n",
    "                node_to_mutate.value = random.uniform(CONST_MIN, CONST_MAX)\n",
    "                node_to_mutate.children = []\n",
    "    \n",
    "    return mutant\n",
    "\n",
    "def hoist_mutation(individual: Node) -> Node:\n",
    "    \"\"\"Performs hoist mutation by replacing the individual with a randomly chosen subtree.\"\"\"\n",
    "    all_nodes = get_all_nodes(individual)\n",
    "    subtrees = [n for n in all_nodes if not n.is_leaf()]\n",
    "\n",
    "    if not subtrees:\n",
    "        return clone_tree(individual)\n",
    "    return clone_tree(random.choice(subtrees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth Tree Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_max_depth(node: Node, max_depth: int = 3, current_depth: int = 0):\n",
    "    \"\"\"It reduces the depth of the tree to a maximum depth.\"\"\"\n",
    "    if current_depth >= max_depth:\n",
    "        if VARIABLES:\n",
    "            node.value = random.choice(VARIABLES + [random.uniform(CONST_MIN, CONST_MAX)])\n",
    "        else:\n",
    "            node.value = random.uniform(CONST_MIN, CONST_MAX)\n",
    "        node.children = []\n",
    "    else:\n",
    "        for c in node.children:\n",
    "            enforce_max_depth(c, max_depth, current_depth+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Programming Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_genetic_programming(x: np.ndarray, y: np.ndarray,\n",
    "                            population_size=50000,\n",
    "                            generations=200,\n",
    "                            elite_size=2,\n",
    "                            max_depth=6):\n",
    "    \"\"\" It executes the genetic programming algorithm. \"\"\"\n",
    "\n",
    "    population = []\n",
    "    half_pop = population_size // 2\n",
    "    for i in range(half_pop):\n",
    "        tree = generate_random_tree(depth=2)\n",
    "        enforce_max_depth(tree, max_depth=max_depth)\n",
    "        population.append(tree)\n",
    "\n",
    "    for i in range(population_size - half_pop):\n",
    "        tree = generate_random_tree(depth=4)\n",
    "        enforce_max_depth(tree, max_depth=max_depth)\n",
    "        population.append(tree)\n",
    "    \n",
    "    best_overall = None\n",
    "    best_fitness = float('inf')\n",
    "    \n",
    "    hall_of_fame = []  \n",
    "\n",
    "    for g in range(generations):\n",
    "        scored_pop = [(ind, fitness(ind, x, y)) for ind in population]\n",
    "        scored_pop.sort(key=lambda x: x[1]) \n",
    "        \n",
    "        best_current, best_current_fit = scored_pop[0]\n",
    "      \n",
    "        if best_current_fit < best_fitness:\n",
    "            best_overall = clone_tree(best_current)\n",
    "            best_fitness = best_current_fit\n",
    "        \n",
    "        best_str = tree_to_string(best_current)\n",
    "        print(f\"[Gen {g}] Best MSE: {best_current_fit:.40f} => {best_str}\")\n",
    "        \n",
    "        hall_of_fame.append((clone_tree(best_current), best_current_fit))\n",
    "        \n",
    "        new_population = [ind for ind, fit in scored_pop[:elite_size]]\n",
    "        \n",
    "        while len(new_population) < population_size:\n",
    "            p1 = tournament_selection(population, x, y, k=3)\n",
    "            p2 = tournament_selection(population, x, y, k=3)\n",
    "            offspring = crossover(p1, p2)\n",
    "            if random.random() < 0.10:\n",
    "                offspring = hoist_mutation(offspring)\n",
    "            else:\n",
    "                offspring = mutation(offspring)\n",
    "            enforce_max_depth(offspring, max_depth=max_depth)\n",
    "            new_population.append(offspring)\n",
    "        \n",
    "        population = new_population\n",
    "    \n",
    "    return best_overall, best_fitness, hall_of_fame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = x_validation.shape[1]\n",
    "print(\"\\nTraining:\\n\")\n",
    "TRAIN_SIZE = N // 10\n",
    "print(f\"TRAIN_SIZE = {TRAIN_SIZE}\")\n",
    "\n",
    "train_indexes = np.random.choice(N, size=TRAIN_SIZE, replace=False)\n",
    "\n",
    "x_train = x_validation[:, train_indexes]\n",
    "y_train = y_validation[train_indexes]\n",
    "\n",
    "population_sizes = [1000, 10_000, 50_000]\n",
    "generations_list = [100, 200]\n",
    "elite_sizes = [2, 4]\n",
    "\n",
    "for pop_size in population_sizes:\n",
    "    for gens in generations_list:\n",
    "        for elite in elite_sizes:\n",
    "            print(f\"\\nTraining with population_size={pop_size}, generations={gens}, elite_size={elite}\")\n",
    "            best_individual_training, best_fit_training, hall_of_fame_training = run_genetic_programming(\n",
    "                x_train, y_train,\n",
    "                population_size=pop_size,\n",
    "                generations=gens,\n",
    "                elite_size=elite,\n",
    "                max_depth=6\n",
    "            )\n",
    "\n",
    "\n",
    "            expr_str_training = tree_to_string(best_individual_training)\n",
    "            print(f\"\\nResults: pop={pop_size}, gen={gens}, elite={elite}\")\n",
    "            print(f\"\\nBest expression found = {expr_str_training}, MSE = {best_fit_training}\")\n",
    "\n",
    "            gx_best_individual_training = convert_to_gxgp_node(best_individual_training)\n",
    "            print(\"Final Expression Tree (GP on training set):\")\n",
    "            file_name = f\"tree_pop{pop_size}_gen{gens}_elite{elite}.png\"\n",
    "            draw(gx_best_individual_training, file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test:\\n\")\n",
    "best_individual, best_fit, hall_of_fame = run_genetic_programming(\n",
    "    x_validation, y_validation,\n",
    "    population_size=50_000,\n",
    "    generations=200,\n",
    "    elite_size=4\n",
    ")\n",
    "print(best_individual)\n",
    "expr_str = tree_to_string(best_individual)\n",
    "print(f\"\\nBest expression found = {expr_str}, MSE = {best_fit}\")\n",
    "\n",
    "gx_best_individual = convert_to_gxgp_node(best_individual)\n",
    "print(\"Final Expression Tree (GP on test set):\")\n",
    "draw(gx_best_individual)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
